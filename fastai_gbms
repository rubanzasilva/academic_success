{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73290,"databundleVersionId":8710574,"sourceType":"competition"},{"sourceId":8574851,"sourceType":"datasetVersion","datasetId":5127429}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classification model to predict students' dropout and academic sucess.\n\nThe dataset contains information collected from a higher education institution related to students undertaking different degree programs.\nThe original dataset contains information known at the time of student enrollment and the student's academic perfromance at the end of the 1st and 2nd semester.\n\nThe target is split into three distinct categories namely Dropout, Enrolled and Graduate.\n\nIn this spirit, I shall build classification models using various architectures to predict the student's dropout and academic success.This can then be used to predict which students are most likely to drop out at an early stage so that strategies can be put in place to counter this.\n\nThat would help reduce the rate of academic dropout and failure.","metadata":{"id":"PnoQ0_VdLaOc"}},{"cell_type":"markdown","source":"## Import Libraries and Datasets","metadata":{"id":"9OxKc8QxLWir"}},{"cell_type":"markdown","source":"### Libraries","metadata":{"id":"fYKulgvoLlxF"}},{"cell_type":"markdown","source":"### Original Dataset\n\n@misc{misc_predict_students'_dropout_and_academic_success_697,\n  author       = {Realinho,Valentim, Vieira Martins,Mónica, Machado,Jorge, and Baptista,Luís},\n  title        = {{Predict Students' Dropout and Academic Success}},\n  year         = {2021},\n  howpublished = {UCI Machine Learning Repository},\n  note         = {{DOI}: https://doi.org/10.24432/C5MC89}\n}","metadata":{"id":"CBvp4q-WRL1O"}},{"cell_type":"markdown","source":"## Imports\n\nBelow, i import all the libraries and datasets needed for this competition.","metadata":{"id":"YRiKSLsk_8Ia"}},{"cell_type":"code","source":"!pip install catboost\n!pip install optuna\n!pip install optuna_distributed\n!pip install openfe","metadata":{"id":"MVFLmLWg_8Ih","outputId":"0f41f00f-df50-4173-a4f0-b30c536499ed","scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-10T15:44:49.531585Z","iopub.execute_input":"2024-06-10T15:44:49.531966Z","iopub.status.idle":"2024-06-10T15:45:59.348186Z","shell.execute_reply.started":"2024-06-10T15:44:49.531936Z","shell.execute_reply":"2024-06-10T15:45:59.346640Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.5)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.5)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.26.4)\nRequirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.11.4)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mCollecting optuna_distributed\n  Downloading optuna_distributed-0.6.2-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: optuna>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from optuna_distributed) (3.6.1)\nRequirement already satisfied: dask[distributed] in /opt/conda/lib/python3.10/site-packages (from optuna_distributed) (2024.5.1)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from optuna_distributed) (13.7.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (2.0.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (4.66.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (6.0.1)\nRequirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (8.1.7)\nRequirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (2.2.1)\nRequirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (2024.3.1)\nRequirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (1.4.2)\nRequirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (0.12.1)\nRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (6.11.0)\nCollecting distributed==2024.5.1 (from dask[distributed]->optuna_distributed)\n  Downloading distributed-2024.5.1-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.1->dask[distributed]->optuna_distributed) (3.1.2)\nRequirement already satisfied: locket>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.1->dask[distributed]->optuna_distributed) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.1->dask[distributed]->optuna_distributed) (1.0.7)\nRequirement already satisfied: psutil>=5.7.2 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.1->dask[distributed]->optuna_distributed) (5.9.3)\nCollecting sortedcontainers>=2.0.5 (from distributed==2024.5.1->dask[distributed]->optuna_distributed)\n  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\nCollecting tblib>=1.6.0 (from distributed==2024.5.1->dask[distributed]->optuna_distributed)\n  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.1->dask[distributed]->optuna_distributed) (6.3.3)\nRequirement already satisfied: urllib3>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.1->dask[distributed]->optuna_distributed) (1.26.18)\nCollecting zict>=3.0.0 (from distributed==2024.5.1->dask[distributed]->optuna_distributed)\n  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->optuna_distributed) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->optuna_distributed) (2.17.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna_distributed) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna_distributed) (4.9.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[distributed]->optuna_distributed) (3.17.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->optuna_distributed) (0.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna>=3.1.0->optuna_distributed) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1.0->optuna_distributed) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed==2024.5.1->dask[distributed]->optuna_distributed) (2.1.3)\nDownloading optuna_distributed-0.6.2-py3-none-any.whl (30 kB)\nDownloading distributed-2024.5.1-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\nDownloading tblib-3.0.0-py3-none-any.whl (12 kB)\nDownloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: sortedcontainers, zict, tblib, distributed, optuna_distributed\nSuccessfully installed distributed-2024.5.1 optuna_distributed-0.6.2 sortedcontainers-2.4.0 tblib-3.0.0 zict-3.0.0\nCollecting openfe\n  Downloading openfe-0.0.12-py3-none-any.whl.metadata (667 bytes)\nRequirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.26.4)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from openfe) (2.2.2)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.2.2)\nRequirement already satisfied: lightgbm>=3.3.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (4.2.0)\nRequirement already satisfied: scipy>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.11.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openfe) (4.66.4)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openfe) (16.1.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->openfe) (1.16.0)\nDownloading openfe-0.0.12-py3-none-any.whl (21 kB)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: openfe\nSuccessfully installed openfe-0.0.12\n","output_type":"stream"}]},{"cell_type":"code","source":"#hide\n#! [ -e /content ]\n\n#hide\n#This imports and sets up everything you will need for this notebook\n#\n#!pip install -Uqq fastbook\n#import fastbook\n#fastbook.setup_book()\n\n#from fastbook import *\n#!pip install ucimlrepo\n#from ucimlrepo import fetch_ucirepo\n\nfrom fastai.tabular.all import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom numpy import random\n\nfrom fastai.imports import *\nnp.set_printoptions(linewidth=130)\n\n\nfrom pathlib import Path\nimport os\n\n\nfrom sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score,accuracy_score,mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error,r2_score\n#from sklearn.metrics import root_mean_squared_error\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\n\nimport lightgbm as lgb\n\nfrom catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n\nfrom ipywidgets import interact\n\n\nmatplotlib.rc('image', cmap='Greys')\n\n#from fastkaggle import setup_comp\n\nimport optuna\nfrom openfe import OpenFE, transform\n\nfrom IPython.display import FileLink\n\n#from lightgbm import LGBMClassifier\n\n","metadata":{"id":"iKvCdJ05_8Im","execution":{"iopub.status.busy":"2024-06-10T15:45:59.352619Z","iopub.execute_input":"2024-06-10T15:45:59.353060Z","iopub.status.idle":"2024-06-10T15:46:02.539742Z","shell.execute_reply.started":"2024-06-10T15:45:59.353018Z","shell.execute_reply":"2024-06-10T15:46:02.538227Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"h4tHhDlX_8Iv","outputId":"9ddbe59f-a542-4564-836c-d02d7a757dd5","execution":{"iopub.status.busy":"2024-06-10T15:46:02.541359Z","iopub.execute_input":"2024-06-10T15:46:02.541770Z","iopub.status.idle":"2024-06-10T15:46:02.554937Z","shell.execute_reply.started":"2024-06-10T15:46:02.541735Z","shell.execute_reply":"2024-06-10T15:46:02.553485Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/academic-success-dataset/data.csv\n/kaggle/input/playground-series-s4e6/sample_submission.csv\n/kaggle/input/playground-series-s4e6/train.csv\n/kaggle/input/playground-series-s4e6/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"path = Path('/kaggle/input/playground-series-s4e6/')\npath","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:46:02.558291Z","iopub.execute_input":"2024-06-10T15:46:02.558705Z","iopub.status.idle":"2024-06-10T15:46:02.581559Z","shell.execute_reply.started":"2024-06-10T15:46:02.558672Z","shell.execute_reply":"2024-06-10T15:46:02.580131Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Path('/kaggle/input/playground-series-s4e6')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Import Datasets","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(path/'train.csv')\ntest_df = pd.read_csv(path/'test.csv')\nsub_df = pd.read_csv(path/'sample_submission.csv')\noriginal_df = pd.read_csv('/kaggle/input/academic-success-dataset/data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:46:02.584083Z","iopub.execute_input":"2024-06-10T15:46:02.585226Z","iopub.status.idle":"2024-06-10T15:46:03.490590Z","shell.execute_reply.started":"2024-06-10T15:46:02.585190Z","shell.execute_reply":"2024-06-10T15:46:03.488953Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#X = train_df.drop(columns=[\"Target\"], axis=1)\n#y = train_df[\"Target\"]\n\n#y.shape, X.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:46:03.492175Z","iopub.execute_input":"2024-06-10T15:46:03.493195Z","iopub.status.idle":"2024-06-10T15:46:03.498195Z","shell.execute_reply.started":"2024-06-10T15:46:03.493149Z","shell.execute_reply":"2024-06-10T15:46:03.496916Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Baseline\n\nPreviously, i had built a baseline model using AutoML solution AutoGluon without presets, this gave me an initial submission score of 0.83434.Find the notebook [here](https://www.kaggle.com/code/rubanzasilva/autogluon-starter).\n\nIn this notebook, i test out different model architectures and data transformation to try to improve on the baseline score.","metadata":{}},{"cell_type":"markdown","source":"# Without original dataset\n\nFirst i shall try out the models using only the data initially provided to us, without the original dataset.\n\nBelow i use the fastai tabular methods to preprocess and prepare my data for machine learning, creating training and a validation set.\n\nUse the fastai cont_cat_split to separate my dataset variables into categorical and continous variables.\n\nI then use randomsplitter to do a random split and create a validation set of about 20% of the initial dataset.\n\n","metadata":{}},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(train_df, dep_var='Target')\nsplits = RandomSplitter(valid_pct=0.2)(range_of(train_df))\nto = TabularPandas(train_df, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='Target',\n                   y_block=CategoryBlock(),\n                   splits=splits)\n\nX_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n\ndls = to.dataloaders(bs=64)\ntest_dl = dls.test_dl(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:46:03.499954Z","iopub.execute_input":"2024-06-10T15:46:03.501009Z","iopub.status.idle":"2024-06-10T15:46:03.990639Z","shell.execute_reply.started":"2024-06-10T15:46:03.500975Z","shell.execute_reply":"2024-06-10T15:46:03.988693Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Random Forests","metadata":{}},{"cell_type":"code","source":"%%time\nrf = RandomForestClassifier(100, min_samples_leaf=3)\nrf_model_a = rf.fit(X_train, y_train);\n\nrf_preds = tensor(rf_model_a.predict(test_dl.xs))\n\nrf_preds_x = tensor(rf_model_a.predict(X_test))\n\n#mse = mean_absolute_error(y_test, rf_preds_x)\n#rmse = np.sqrt(mse)\n\naccuracy_score(y_test,rf_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:51:06.861223Z","iopub.execute_input":"2024-06-10T15:51:06.861976Z","iopub.status.idle":"2024-06-10T15:51:24.999049Z","shell.execute_reply.started":"2024-06-10T15:51:06.861930Z","shell.execute_reply":"2024-06-10T15:51:24.997794Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"CPU times: user 18 s, sys: 52.4 ms, total: 18.1 s\nWall time: 18.1 s\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.8207541005031693"},"metadata":{}}]},{"cell_type":"markdown","source":"## Cat Preds","metadata":{}},{"cell_type":"code","source":"%%time\ncat_model = CatBoostClassifier(iterations=2000, depth=8, learning_rate=  0.08, random_strength=10)\ncat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n\n#test set preds\ncat_preds = tensor(cat_model.predict(test_dl.xs))\n\n\ncat_preds_final = cat_preds.squeeze(1)\n\n#validation set preds\ncat_preds_x = tensor(cat_model.predict(X_test))\n\naccuracy_score(y_test,cat_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:46:03.992400Z","iopub.execute_input":"2024-06-10T15:46:03.992779Z","iopub.status.idle":"2024-06-10T15:50:01.138443Z","shell.execute_reply.started":"2024-06-10T15:46:03.992747Z","shell.execute_reply":"2024-06-10T15:50:01.136953Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"CPU times: user 10min 53s, sys: 14.6 s, total: 11min 7s\nWall time: 3min 57s\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0.8253937136509181"},"metadata":{}}]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(n_estimators = 197, max_depth=4, learning_rate=0.1818695751227044, subsample= 0.39774994666482544)\nxgb_model = xgb_model.fit(X_train, y_train)\n\nxgb_preds = tensor(xgb_model.predict(test_dl.xs))\n\nxgb_preds_x = tensor(xgb_model.predict(X_test))\n\naccuracy_score(y_test,xgb_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:50:01.140020Z","iopub.execute_input":"2024-06-10T15:50:01.140426Z","iopub.status.idle":"2024-06-10T15:50:09.701580Z","shell.execute_reply.started":"2024-06-10T15:50:01.140386Z","shell.execute_reply":"2024-06-10T15:50:09.700019Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0.8247402470103902"},"metadata":{}}]},{"cell_type":"markdown","source":"## LGBM","metadata":{}},{"cell_type":"code","source":"lgb_model = lgb.LGBMClassifier(num_leaves=251, learning_rate=0.02956613668999794, n_estimators=483, max_depth=82, boosting_type='gbdt',min_child_samples=90, random_state=27)\nlgb_model = lgb_model.fit(X_train, y_train)\n\n#test set preds\nlgb_preds = tensor(lgb_model.predict(test_dl.xs))\n\n#validation set preds\nlgb_preds_x = tensor(lgb_model.predict(X_test))\n\nlgb_score = accuracy_score(y_test,lgb_preds_x)\nlgb_score","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:50:09.706166Z","iopub.execute_input":"2024-06-10T15:50:09.706683Z","iopub.status.idle":"2024-06-10T15:51:06.859418Z","shell.execute_reply.started":"2024-06-10T15:50:09.706637Z","shell.execute_reply":"2024-06-10T15:51:06.858152Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019012 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1652\n[LightGBM] [Info] Number of data points in the train set: 61215, number of used features: 37\n[LightGBM] [Info] Start training from score -1.108314\n[LightGBM] [Info] Start training from score -1.637854\n[LightGBM] [Info] Start training from score -0.743414\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.8246095536822845"},"metadata":{}}]},{"cell_type":"code","source":"model_preds = {\n    \"random forests\":accuracy_score(y_test,rf_preds_x),\n    \"cat boost\":accuracy_score(y_test,cat_preds_x),\n    \"lgbm\":lgb_score,\n    \"xgboost\":accuracy_score(y_test,xgb_preds_x),   \n}\n\n#model_preds_a = model_preds.sort()\nprint(model_preds)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:51:25.000723Z","iopub.execute_input":"2024-06-10T15:51:25.001173Z","iopub.status.idle":"2024-06-10T15:51:25.013690Z","shell.execute_reply.started":"2024-06-10T15:51:25.001133Z","shell.execute_reply":"2024-06-10T15:51:25.012479Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'random forests': 0.8207541005031693, 'cat boost': 0.8253937136509181, 'lgbm': 0.8246095536822845, 'xgboost': 0.8247402470103902}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"{'random forests': 0.826439260275763, 'cat boost': 0.8316016467359342, 'lgbm': 0.8306214467751422, 'xgboost': 0.8299679801346141}","metadata":{}},{"cell_type":"code","source":"mapping = dict(enumerate(dls.vocab))\nmapping","metadata":{"execution":{"iopub.status.busy":"2024-06-10T08:18:37.930959Z","iopub.execute_input":"2024-06-10T08:18:37.931539Z","iopub.status.idle":"2024-06-10T08:18:37.940312Z","shell.execute_reply.started":"2024-06-10T08:18:37.931496Z","shell.execute_reply":"2024-06-10T08:18:37.938849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"lgb_preds.shape,cat_preds.shape,cat_preds_final.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:56:55.807458Z","iopub.execute_input":"2024-06-10T15:56:55.807894Z","iopub.status.idle":"2024-06-10T15:56:55.815942Z","shell.execute_reply.started":"2024-06-10T15:56:55.807863Z","shell.execute_reply":"2024-06-10T15:56:55.814653Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(torch.Size([51012]), torch.Size([51012, 1]), torch.Size([51012]))"},"metadata":{}}]},{"cell_type":"code","source":"mapping = dict(enumerate(dls.vocab))\npredicted_labels = [mapping[value.item()] for value in cat_preds_final]\nsubmit = pd.read_csv(path/'sample_submission.csv')\nsubmit.Target = predicted_labels\nsubmit.to_csv('submission.csv',index=False)\nsubmit","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:57:08.705158Z","iopub.execute_input":"2024-06-10T15:57:08.705740Z","iopub.status.idle":"2024-06-10T15:57:09.211859Z","shell.execute_reply.started":"2024-06-10T15:57:08.705696Z","shell.execute_reply":"2024-06-10T15:57:09.210532Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"           id    Target\n0       76518   Dropout\n1       76519  Graduate\n2       76520  Graduate\n3       76521  Enrolled\n4       76522  Enrolled\n...       ...       ...\n51007  127525   Dropout\n51008  127526   Dropout\n51009  127527   Dropout\n51010  127528   Dropout\n51011  127529   Dropout\n\n[51012 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>76518</td>\n      <td>Dropout</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>76519</td>\n      <td>Graduate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>76520</td>\n      <td>Graduate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76521</td>\n      <td>Enrolled</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>76522</td>\n      <td>Enrolled</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51007</th>\n      <td>127525</td>\n      <td>Dropout</td>\n    </tr>\n    <tr>\n      <th>51008</th>\n      <td>127526</td>\n      <td>Dropout</td>\n    </tr>\n    <tr>\n      <th>51009</th>\n      <td>127527</td>\n      <td>Dropout</td>\n    </tr>\n    <tr>\n      <th>51010</th>\n      <td>127528</td>\n      <td>Dropout</td>\n    </tr>\n    <tr>\n      <th>51011</th>\n      <td>127529</td>\n      <td>Dropout</td>\n    </tr>\n  </tbody>\n</table>\n<p>51012 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-06-10T15:57:11.325114Z","iopub.execute_input":"2024-06-10T15:57:11.325530Z","iopub.status.idle":"2024-06-10T15:57:12.482368Z","shell.execute_reply.started":"2024-06-10T15:57:11.325500Z","shell.execute_reply":"2024-06-10T15:57:12.480655Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"catboost_info  state.db  submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!kaggle competitions submit -c kagglex-cohort4 -f submission.csv -m \"general_preds baseline\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm submission.csv","metadata":{"execution":{"iopub.status.busy":"2024-06-06T19:54:19.276169Z","iopub.execute_input":"2024-06-06T19:54:19.276677Z","iopub.status.idle":"2024-06-06T19:54:20.412008Z","shell.execute_reply.started":"2024-06-06T19:54:19.276636Z","shell.execute_reply":"2024-06-06T19:54:20.410359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Neural Network","metadata":{"id":"dYNkzV6z_8JO"}},{"cell_type":"code","source":"learn = tabular_learner(dls, metrics=accuracy)\nlearn.lr_find(suggest_funcs=(slide,valley))","metadata":{"id":"X0LRKpxq_8JO","execution":{"iopub.status.busy":"2024-06-10T08:56:00.352058Z","iopub.execute_input":"2024-06-10T08:56:00.353234Z","iopub.status.idle":"2024-06-10T08:56:02.896700Z","shell.execute_reply.started":"2024-06-10T08:56:00.353186Z","shell.execute_reply":"2024-06-10T08:56:02.895396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlearn.fit_one_cycle(20,0.02)","metadata":{"id":"igxsaxjb_8JU","execution":{"iopub.status.busy":"2024-06-10T08:56:07.418850Z","iopub.execute_input":"2024-06-10T08:56:07.419347Z","iopub.status.idle":"2024-06-10T09:00:29.171898Z","shell.execute_reply.started":"2024-06-10T08:56:07.419305Z","shell.execute_reply":"2024-06-10T09:00:29.170385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dl = learn.dls.test_dl(test_df)","metadata":{"id":"xpiUqiLF_8JV","execution":{"iopub.status.busy":"2024-06-10T09:21:50.309613Z","iopub.execute_input":"2024-06-10T09:21:50.310417Z","iopub.status.idle":"2024-06-10T09:21:50.464754Z","shell.execute_reply.started":"2024-06-10T09:21:50.310368Z","shell.execute_reply":"2024-06-10T09:21:50.463551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nnn_preds = learn.get_preds(dl=dl)\nnn_preds_x = learn.get_preds()[0]\na_preds, _ = learn.get_preds(dl=dl)\nnn_preds_y = a_preds.squeeze(1)","metadata":{"id":"ASXsRveD_8JW","execution":{"iopub.status.busy":"2024-06-10T09:21:51.971295Z","iopub.execute_input":"2024-06-10T09:21:51.971826Z","iopub.status.idle":"2024-06-10T09:22:05.290230Z","shell.execute_reply.started":"2024-06-10T09:21:51.971787Z","shell.execute_reply":"2024-06-10T09:22:05.288566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_preds_final = cat_preds.squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T09:36:44.355090Z","iopub.execute_input":"2024-06-10T09:36:44.355624Z","iopub.status.idle":"2024-06-10T09:36:44.362535Z","shell.execute_reply.started":"2024-06-10T09:36:44.355582Z","shell.execute_reply":"2024-06-10T09:36:44.360721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds_x.shape,cat_preds.shape,cat_preds_final.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-10T09:36:45.564229Z","iopub.execute_input":"2024-06-10T09:36:45.565475Z","iopub.status.idle":"2024-06-10T09:36:45.573110Z","shell.execute_reply.started":"2024-06-10T09:36:45.565408Z","shell.execute_reply":"2024-06-10T09:36:45.571698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-06-10T09:46:39.951817Z","iopub.execute_input":"2024-06-10T09:46:39.952485Z","iopub.status.idle":"2024-06-10T09:46:40.993122Z","shell.execute_reply.started":"2024-06-10T09:46:39.952416Z","shell.execute_reply":"2024-06-10T09:46:40.991497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm submission.csv","metadata":{"execution":{"iopub.status.busy":"2024-06-10T09:41:09.743546Z","iopub.execute_input":"2024-06-10T09:41:09.745021Z","iopub.status.idle":"2024-06-10T09:41:10.803569Z","shell.execute_reply.started":"2024-06-10T09:41:09.744960Z","shell.execute_reply":"2024-06-10T09:41:10.801056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = dict(enumerate(dls.vocab))\npredicted_labels = [mapping[value.item()] for value in cat_preds_final]\nsubmit = pd.read_csv(path/'sample_submission.csv')\nsubmit.Target = predicted_labels\nsubmit.to_csv('submission.csv',index=False)\nsubmit","metadata":{"id":"KB9WcsyA_8Jk","execution":{"iopub.status.busy":"2024-06-10T09:46:44.413471Z","iopub.execute_input":"2024-06-10T09:46:44.414025Z","iopub.status.idle":"2024-06-10T09:46:44.641955Z","shell.execute_reply.started":"2024-06-10T09:46:44.413980Z","shell.execute_reply":"2024-06-10T09:46:44.640504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding Base Features\n\nfrom https://www.kaggle.com/code/trupologhelper/ps4e5-openfe-blending-explain#Creating-New-Features-%F0%9F%93%8A","metadata":{"id":"3HW24rFQ_8KK"}},{"cell_type":"code","source":"BASE_FEATURES = test_final.columns\ninitial_features = BASE_FEATURES\ninitial_features","metadata":{"id":"v10RL0wc_8KN","outputId":"8ec3c1d9-0810-446c-f0e5-67458a52da1f","execution":{"iopub.status.busy":"2024-06-10T10:07:55.376915Z","iopub.execute_input":"2024-06-10T10:07:55.377520Z","iopub.status.idle":"2024-06-10T10:07:55.432836Z","shell.execute_reply.started":"2024-06-10T10:07:55.377482Z","shell.execute_reply":"2024-06-10T10:07:55.431034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor df in [train_final, test_final]:\n    print('comnputing f_sum')\n    df['fsum'] = df[initial_features].sum(axis=1) # for tree models\n    print('comnputing f_std')\n    df['f_std']  = df[initial_features].std(axis=1)\n    print('comnputing f_mean')\n    df['f_mean'] = df[initial_features].mean(axis=1)\n    print('comnputing f_max')\n    df['f_max']  = df[initial_features].max(axis=1)\n    print('comnputing f_min')\n    df['f_min']  = df[initial_features].min(axis=1)\n    print('comnputing f_mode')\n    df['f_mode'] = df[initial_features].mode(axis=1)[0]\n    print('comnputing f_median')\n    df['f_median'] = df[initial_features].median(axis=1)\n    print('comnputing f_25th')\n    df['f_25th'] = df[initial_features].quantile(0.25, axis=1)\n    print('comnputing f_75th')\n    df['f_75th'] = df[initial_features].quantile(0.75, axis=1)\n    print('comnputing f_skew')\n    df['f_skew'] = df[initial_features].skew(axis=1)\n    print('comnputing f_kurt')\n    df['f_kurt'] = df[initial_features].kurt(axis=1)\n    df['special1'] = df['fsum'].isin(np.arange(72, 76)) # for linear models\n    for i in range(10,100,10):\n        print(f'comnputing f_{i}th')\n        df[f'f_{i}th'] = df[initial_features].quantile(i/100, axis=1)\n    print('comnputing f_harmonic')\n    df['f_harmonic'] = len(initial_features) / df[initial_features].apply(lambda x: (1/x).mean(), axis=1)\n    print('comnputing f_geometric')\n    df['f_geometric'] = df[initial_features].apply(lambda x: x.prod()**(1/len(x)), axis=1)\n    print('comnputing f_zscore')\n    df['f_zscore'] = df[initial_features].apply(lambda x: (x - x.mean()) / x.std(), axis=1).mean(axis=1)\n    print('computing Coefficient of Variation ')\n    df['f_cv'] = df[initial_features].std(axis=1) / df[initial_features].mean(axis=1)\n    print('computing f_Quantile Coefficients of Skewness_75')\n    df['f_Quantile Coefficients of Skewness_75'] = (df[initial_features].quantile(0.75, axis=1) - df[initial_features].mean(axis=1)) / df[initial_features].std(axis=1)\n    print('computing f_Quantile Coefficients of Skewness_25')\n    df['f_Quantile Coefficients of Skewness_25'] = (df[initial_features].quantile(0.25, axis=1) - df[initial_features].mean(axis=1)) / df[initial_features].std(axis=1)\n    print('computing f_2ndMoment')\n    df['f_2ndMoment'] = df[initial_features].apply(lambda x: (x**2).mean(), axis=1)\n    print('computing f_3rdMoment')\n    df['f_3rdMoment'] = df[initial_features].apply(lambda x: (x**3).mean(), axis=1)\n    print('computing f_entropy')\n    df['f_entropy'] = df[initial_features].apply(lambda x: -1*(x*np.log(x)).sum(), axis=1)\n    #print('computing f_mad') probably has negative impact\n    #df['f_mad'] = df[initial_features].apply(lambda x: (x - x.median()).abs().median(), axis=1)\n    #print('computing f_iqr') probably has negative impact\n    #df['f_iqr'] = df[initial_features].quantile(0.75, axis=1) - df[initial_features].quantile(0.25, axis=1)","metadata":{"id":"VjTG3tHd_8KO","outputId":"5470631f-b68e-4740-9c3d-fae9a7ee3113","scrolled":true,"execution":{"iopub.status.busy":"2024-06-10T10:08:04.809801Z","iopub.execute_input":"2024-06-10T10:08:04.810255Z","iopub.status.idle":"2024-06-10T10:08:04.926197Z","shell.execute_reply.started":"2024-06-10T10:08:04.810222Z","shell.execute_reply":"2024-06-10T10:08:04.924897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_final.head()","metadata":{"id":"pOHguGRO_8KR","outputId":"c721b318-d445-46c1-c36a-bac6827081cd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Network Ensemble","metadata":{"id":"75E_pjgO_8LW"}},{"cell_type":"code","source":"def ensemble():\n    learn = tabular_learner(dls, metrics=accuracy)\n    with learn.no_bar(),learn.no_logging(): learn.fit(6, 0.02)\n    return learn.get_preds(dl=dl)[0]","metadata":{"id":"Gsi88cA5_8LX","execution":{"iopub.status.busy":"2024-06-10T10:27:37.349831Z","iopub.execute_input":"2024-06-10T10:27:37.350397Z","iopub.status.idle":"2024-06-10T10:27:37.357499Z","shell.execute_reply.started":"2024-06-10T10:27:37.350357Z","shell.execute_reply":"2024-06-10T10:27:37.356107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learns = [ensemble() for _ in range(5)]","metadata":{"id":"wK8O6o3L_8LX","execution":{"iopub.status.busy":"2024-06-10T10:27:37.519049Z","iopub.execute_input":"2024-06-10T10:27:37.519559Z","iopub.status.idle":"2024-06-10T10:34:07.203058Z","shell.execute_reply.started":"2024-06-10T10:27:37.519518Z","shell.execute_reply":"2024-06-10T10:34:07.201710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_preds = torch.stack(learns).mean(0)","metadata":{"id":"xUlI9CSG_8LY","execution":{"iopub.status.busy":"2024-06-10T10:34:07.205893Z","iopub.execute_input":"2024-06-10T10:34:07.206424Z","iopub.status.idle":"2024-06-10T10:34:07.218108Z","shell.execute_reply.started":"2024-06-10T10:34:07.206380Z","shell.execute_reply":"2024-06-10T10:34:07.216762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds_x.shape,ens_preds.shape","metadata":{"id":"bbGl6BUp_8LZ","execution":{"iopub.status.busy":"2024-06-10T10:38:47.213699Z","iopub.execute_input":"2024-06-10T10:38:47.214931Z","iopub.status.idle":"2024-06-10T10:38:47.222872Z","shell.execute_reply.started":"2024-06-10T10:38:47.214883Z","shell.execute_reply":"2024-06-10T10:38:47.221549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming ens_preds is a PyTorch tensor with shape [51012, 3]\n# Select predictions for the first class (index 0)\nselected_class_preds = ens_preds[:, 0]\n\n# Now selected_class_preds has a shape of torch.Size([51012])\nprint(selected_class_preds.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:44:58.684787Z","iopub.execute_input":"2024-06-10T10:44:58.685309Z","iopub.status.idle":"2024-06-10T10:44:58.692391Z","shell.execute_reply.started":"2024-06-10T10:44:58.685279Z","shell.execute_reply":"2024-06-10T10:44:58.691132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_preds_final = ens_preds.squeeze(1)\nens_preds_final.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:39:58.129053Z","iopub.execute_input":"2024-06-10T10:39:58.129582Z","iopub.status.idle":"2024-06-10T10:39:58.138111Z","shell.execute_reply.started":"2024-06-10T10:39:58.129546Z","shell.execute_reply":"2024-06-10T10:39:58.136725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2_score(y_test,nn_preds_x)","metadata":{"id":"akcVt1Od_8LZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_preds = nn_preds[0]","metadata":{"id":"U_6Z8qnF_8La"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['FloodProbability'] = target_preds","metadata":{"id":"Y_hOZQRf_8La"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('submission.csv', columns=['FloodProbability'], index=True)","metadata":{"id":"zdr1ZYj3_8Lc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('submission.csv')\nsubmission.head()","metadata":{"id":"5iqvRPLv_8Lc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm submission.csv","metadata":{"id":"LxMooaAj_8Ld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['FloodProbability'] = target_preds\ntest_df.to_csv('submission.csv', columns=['FloodProbability'], index=True)\n\nsubmission = pd.read_csv('submission.csv')\nsubmission.head()","metadata":{"id":"FwUDs3as_8Lf"},"execution_count":null,"outputs":[]}]}